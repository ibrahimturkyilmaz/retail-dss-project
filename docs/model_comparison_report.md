# ğŸ“Š Faz 3: Model KarÅŸÄ±laÅŸtÄ±rmasÄ± â€” Prophet vs XGBoost

**Proje:** RetailDSS â€” AkÄ±llÄ± Perakende Karar Destek Sistemi  
**Tarih:** 2026-02-15  

---

## 1. AmaÃ§

Ä°ki farklÄ± makine Ã¶ÄŸrenmesi modelinin (Facebook Prophet ve XGBoost) perakende satÄ±ÅŸ tahmini performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±rarak, hangi modelin hangi koÅŸullarda daha baÅŸarÄ±lÄ± olduÄŸunu belirlemek.

---

## 2. GeliÅŸtirme PlanÄ±

### AdÄ±m 1: Veri HazÄ±rlÄ±ÄŸÄ±
- Mevcut `sales_s1_p1.csv` verisini kullan (2 yÄ±l, 730 gÃ¼n)
- Feature engineering:
  - **Zaman Ã¶zellikleri:** `day_of_week`, `month`, `is_weekend`, `quarter`
  - **Lag Ã¶zellikleri:** `lag_1`, `lag_7`, `lag_30` (geÃ§miÅŸ satÄ±ÅŸlar)
  - **Rolling Ã¶zellikleri:** `rolling_mean_7`, `rolling_std_7`
  - **DÄ±ÅŸ deÄŸiÅŸkenler:** `temperature`, `rain` (Open-Meteo API)

### AdÄ±m 2: XGBoost Model EÄŸitimi (Google Colab)
```python
import xgboost as xgb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Feature matrix oluÅŸtur
features = ['day_of_week', 'month', 'is_weekend', 'quarter',
            'lag_1', 'lag_7', 'lag_30',
            'rolling_mean_7', 'rolling_std_7',
            'temperature', 'rain']

X = df[features]
y = df['y']

# Zaman serisi cross-validation (5 fold)
tscv = TimeSeriesSplit(n_splits=5)

model = xgb.XGBRegressor(
    n_estimators=500,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    early_stopping_rounds=50,
    random_state=42
)

# EÄŸitim + deÄŸerlendirme
for train_idx, test_idx in tscv.split(X):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
    
    model.fit(X_train, y_train, 
              eval_set=[(X_test, y_test)], 
              verbose=False)
```

### AdÄ±m 3: Prophet Model EÄŸitimi (Mevcut)
- `interval_width=0.5`, `changepoint_prior_scale=0.01`
- Hava durumu regressÃ¶rleri (sÄ±caklÄ±k + yaÄŸÄ±ÅŸ)
- TÃ¼rkiye tatilleri

### AdÄ±m 4: Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Metrik | AÃ§Ä±klama | FormÃ¼l |
|--------|----------|--------|
| **MAE** | Ortalama Mutlak Hata | `mean(|y - Å·|)` |
| **RMSE** | KÃ¶k Ortalama Kare Hata | `sqrt(mean((y - Å·)Â²))` |
| **MAPE** | YÃ¼zde Cinsinden Hata | `mean(|y - Å·| / y) Ã— 100` |
| **RÂ²** | AÃ§Ä±klanan Varyans OranÄ± | `1 - SS_res / SS_tot` |

```python
# KarÅŸÄ±laÅŸtÄ±rma sonuÃ§larÄ±nÄ± CSV'ye kaydet
comparison = pd.DataFrame({
    'Model': ['Prophet', 'XGBoost'],
    'MAE': [prophet_mae, xgb_mae],
    'RMSE': [prophet_rmse, xgb_rmse],
    'MAPE': [prophet_mape, xgb_mape],
    'R2': [prophet_r2, xgb_r2],
    'Training_Time_Sec': [prophet_time, xgb_time]
})
comparison.to_csv('model_comparison.csv', index=False)
```

### AdÄ±m 5: Feature Importance (XGBoost AvantajÄ±)
```python
import matplotlib.pyplot as plt

# XGBoost feature importance grafiÄŸi
fig, ax = plt.subplots(figsize=(10, 6))
xgb.plot_importance(model, ax=ax, importance_type='gain', max_num_features=10)
plt.title('XGBoost â€” Ã–zellik Ã–nem SÄ±ralamasÄ±')
plt.tight_layout()
plt.savefig('feature_importance.png', dpi=150)
```

### AdÄ±m 6: Frontend Entegrasyonu
- Model & AI sekmesine karÅŸÄ±laÅŸtÄ±rma tablosu ekle
- Her iki modelin MAPE grafiÄŸi (bar chart)
- Feature importance gÃ¶rselleÅŸtirme

---

## 3. Beklenen SonuÃ§lar

| Ã–zellik | Prophet | XGBoost |
|---------|---------|---------|
| **GÃ¼Ã§lÃ¼ YÃ¶nÃ¼** | Trend + Mevsimsellik ayrÄ±ÅŸtÄ±rmasÄ±, tatil etkisi | KarmaÅŸÄ±k non-linear iliÅŸkiler, feature engineering |
| **ZayÄ±f YÃ¶nÃ¼** | Ã‡ok deÄŸiÅŸkenli iliÅŸkilerde sÄ±nÄ±rlÄ± | MevsimselliÄŸi kendisi Ã¶ÄŸrenemez (manual feature gerek) |
| **EÄŸitim SÃ¼resi** | ~30 sn | ~5 sn |
| **Yorumlanabilirlik** | YÃ¼ksek (decomposition) | Orta (SHAP/feature importance) |
| **En Ä°yi Senaryo** | GÃ¼Ã§lÃ¼ mevsimsellik + tatil etkisi | Ã‡ok sayÄ±da dÄ±ÅŸ deÄŸiÅŸken + non-linear patternlar |

### Beklenen MAPE AralÄ±ÄŸÄ±
- **Prophet:** %15-25 (mevsimsellik gÃ¼Ã§lÃ¼ olduÄŸunda daha iyi)
- **XGBoost:** %10-20 (yeterli feature engineering ile daha iyi)

---

## 4. Akademik Kaynaklar

| # | Kaynak | Ä°lgisi |
|---|--------|--------|
| [1] | **Chen, T., & Guestrin, C. (2016).** "XGBoost: A Scalable Tree Boosting System." *KDD '16*, 785-794. | XGBoost'un orijinal makalesi. |
| [2] | **Taylor, S. J., & Letham, B. (2018).** "Forecasting at Scale." *The American Statistician*, 72(1). | Prophet'in orijinal makalesi. |
| [3] | **Makridakis, S., et al. (2018).** "Statistical and ML Forecasting Methods." *PLOS ONE*. | Ä°ki yaklaÅŸÄ±mÄ±n karÅŸÄ±laÅŸtÄ±rmasÄ±. |
| [4] | **Fildes, R., et al. (2022).** "Forecasting Competitions: Their Role in Advancing Forecasting." *IJF*. | Model karÅŸÄ±laÅŸtÄ±rma metodolojisi. |
| [5] | **Ceylan, S. (2024).** "Perakende SatÄ±ÅŸ Tahmini." *YTÃœ, YL Tezi.* | TÃ¼rkÃ§e perakende ML karÅŸÄ±laÅŸtÄ±rmasÄ±. |
| [6] | **Lundberg, S. M., & Lee, S. I. (2017).** "A Unified Approach to Interpreting Model Predictions." *NeurIPS.* | SHAP â€” XGBoost yorumlanabilirlik. |

---

## 5. Dosya YapÄ±sÄ±

```
retail-dss-project/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ prophet_optimization_report.md    â† Mevcut
â”‚   â””â”€â”€ model_comparison_report.md        â† Yeni (bu dosya)
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ import_forecasts.py               â† Mevcut
â”‚   â””â”€â”€ main.py                           â† /comparison endpoint
â””â”€â”€ frontend/
    â””â”€â”€ src/pages/Settings.jsx            â† KarÅŸÄ±laÅŸtÄ±rma UI
```
